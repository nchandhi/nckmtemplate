{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1bff8-6bc6-4c3a-af18-cf590ba2c1e6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019c519-b4ac-4c9f-a2a2-ebd412fd3dcf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# get Azure AI credentials from keyvalut\n",
    "from trident_token_library_wrapper import PyTridentTokenLibrary as tl\n",
    "key_vault_name = 'kv_to-be-replaced'\n",
    "\n",
    "def get_secrets_from_kv(kv_name, secret_name):\n",
    "    access_token = mssparkutils.credentials.getToken(\"keyvault\")\n",
    "    kv_endpoint = f'https://{kv_name}.vault.azure.net/'\n",
    "    return(tl.get_secret_with_token(kv_endpoint,secret_name,access_token))\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-CU-ENDPOINT\")\n",
    "api_key = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-CU-KEY\")\n",
    "\n",
    "# client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6beb49-4fed-4f7c-9813-93e90a078c14",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Set content understanding service settings\n",
    "AISERVICE_ENDPOINT = endpoint\n",
    "API_KEY = api_key\n",
    "API_VERSION = \"?api-version=2024-12-01-preview\"\n",
    "\n",
    "# Set Content Understanding management api paths\n",
    "PATH_ANALYZER_MANAGEMENT_ALL = \"/contentunderstanding/analyzers\"\n",
    "PATH_ANALYZER_MANAGEMENT = \"/contentunderstanding/analyzers/{analyzerId}\"\n",
    "PATH_ANALYZER_MANAGEMENT_OPERATION = \"/contentunderstanding/analyzers/{analyzerId}/operations/{operationId}\"\n",
    "\n",
    "# Set Content Understanding inference paths\n",
    "PATH_ANALYZER_INFERENCE = \"/contentunderstanding/analyzers/{analyzerId}:analyze\"\n",
    "PATH_ANALYZER_INFERENCE_GET_IMAGE = \"/contentunderstanding/analyzers/{analyzerId}/results/{operationId}/images/{imageId}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa0b6a-2fac-4eae-a32f-4e24748382a0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# helper method to poll for inferencing results\n",
    "def poll_for_results(operation_location: str, success_state: str, failed_state: str, timeout: int = 300, interval: int = 2):\n",
    "    \"\"\"\n",
    "    Polls the operation location URL until the operation reaches a success or failure state.\n",
    "\n",
    "    Args:\n",
    "        operation_location (str): The URL to poll for the operation result.\n",
    "        success_state (str): The status indicating the operation succeeded.\n",
    "        failed_state (str): The status indicating the operation failed.\n",
    "        timeout (int, optional): Maximum time to wait in seconds. Default is 60 seconds.\n",
    "        interval (int, optional): Time between polling attempts in seconds. Default is 2 seconds.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The final JSON response if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': API_KEY,\n",
    "        'cogsvc-videoanalysis-face-identification-enable': \"true\"\n",
    "    }\n",
    "\n",
    "    # print(f'GET {operation_location}')\n",
    "\n",
    "    elapsed_time = 0\n",
    "    while elapsed_time <= timeout:\n",
    "        try:\n",
    "            response = requests.get(operation_location, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            # print(response)\n",
    "            # print(result)\n",
    "\n",
    "            status = result.get('status')\n",
    "            if status == success_state:\n",
    "                return result\n",
    "            elif status == failed_state:\n",
    "                print(f\"Operation failed with status: {status}\")\n",
    "                return None\n",
    "\n",
    "            time.sleep(interval)\n",
    "            elapsed_time += interval\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    print(\"Operation timed out.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560dbb2-000f-4b0c-9f2b-9ba3c5f727e1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def listAllfilesinPath(directory) -> List[str]:\n",
    "    return [join(directory, f) for f in listdir(directory) if (isfile(join(directory, f)) and not f.endswith('.json'))]\n",
    "\n",
    "def loadAnalyzerfromFile(path, analyzer_name) -> dict:\n",
    "    with open(path) as json_file:\n",
    "        analyzer = json.load(json_file)\n",
    "    analyzer['analyzerId'] = analyzer_name\n",
    "    return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f6b49-e05c-4424-be1e-d5886b40f3ee",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# helper method to create an analyzer\n",
    "def create_analyzer(analyzer_config: str):\n",
    "    print(f\"Creating analyzer with id: {analyzer_config['analyzerId']}\")\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': API_KEY,\n",
    "        'Content-Type': 'application/json',\n",
    "        'cogsvc-videoanalysis-face-identification-enable': \"true\"\n",
    "    }\n",
    "    print(f\"PUT {AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzer_config['analyzerId'])}\")\n",
    "    \n",
    "    response = requests.put(AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzer_config[\"analyzerId\"]) + API_VERSION, headers=headers, json=analyzer_config)\n",
    "    if ('apim-request-id' in response.headers):\n",
    "        print(f\"request-id: {response.headers['apim-request-id']}\")\n",
    "    print(response)\n",
    "    if response.status_code == 201:\n",
    "        final_state = poll_for_results(response.headers['Operation-Location'], 'Succeeded', 'Failed')\n",
    "    else:\n",
    "        final_state = response.json()\n",
    "        print(final_state)\n",
    "    \n",
    "# helper method to delete an analyzer\n",
    "def delete_analyzer(analyzer_config: str):\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': API_KEY,\n",
    "        'Content-Type': 'application/json',\n",
    "        'cogsvc-videoanalysis-face-identification-enable': \"true\"\n",
    "    }\n",
    "    print(f\"DELETE {AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzer_config['analyzerId'])}\")\n",
    "    \n",
    "    response = requests.delete(AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzer_config[\"analyzerId\"]) + API_VERSION, headers=headers)\n",
    "    if ('apim-request-id' in response.headers):\n",
    "        print(f\"request-id: {response.headers['apim-request-id']}\")\n",
    "    print(response)\n",
    "\n",
    "# helper method to patch (update) an analyzer\n",
    "def patch_analyzer(analyzer_config: str):\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': API_KEY,\n",
    "        'Content-Type': 'application/json',\n",
    "        'cogsvc-videoanalysis-face-identification-enable': \"true\"\n",
    "    }\n",
    "    \n",
    "    print(f\"PATCH {AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzer_config['analyzerId'])}\")\n",
    "    \n",
    "    response = requests.patch(AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzer_config[\"analyzerId\"]) + API_VERSION, headers=headers)\n",
    "    if ('apim-request-id' in response.headers):\n",
    "        print(f\"request-id: {response.headers['apim-request-id']}\")\n",
    "    print(response)\n",
    "    \n",
    "# helper method to list all analyzers\n",
    "def list_all_analyzer():\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT_ALL + API_VERSION , headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# helper method to list all analyzers\n",
    "def list_analyzer(analyzerId):\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(AISERVICE_ENDPOINT + PATH_ANALYZER_MANAGEMENT.format(analyzerId=analyzerId) + API_VERSION, headers=headers)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d10814-6d10-4296-8842-90eaad7964e6",
   "metadata": {},
   "source": [
    "## Setup Analyzer from schema file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647625f4-b35d-486f-b34f-292c43368db5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Load an Analyzer from a file\n",
    "mmi_analyzer_file = loadAnalyzerfromFile(\"/lakehouse/default/Files/cu_analyzer_file/ckm-analyzer_config.json\", \"ckm-analyzer\")\n",
    "\n",
    "# delete any existing analyzers\n",
    "analyzers = list_all_analyzer()\n",
    "# print(analyzers['value'])\n",
    "for analyzer in analyzers['value']:\n",
    "    if analyzer.get('analyzerId').startswith('prebuilt'):\n",
    "        continue\n",
    "    print(analyzer.get('analyzerId'))\n",
    "    delete_result = delete_analyzer(analyzer)\n",
    "    print(delete_result)\n",
    "\n",
    "\n",
    "if mmi_analyzer_file == None:\n",
    "    print(\"Skipping. Please set the analyzer_name.\")\n",
    "else:\n",
    "\t# Get timestamp and create output folder\n",
    "\ttimestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\tif \"baseAnalyzerId\" in mmi_analyzer_file:\n",
    "\t\tprint(\"ERROR: Base Analyzer config found!\")\n",
    "\t\texit(0)\n",
    "\telse:\n",
    "\t\tcreate_analyzer(mmi_analyzer_file)\t\t\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {
    "environmentId": "da011a17-6179-42a7-9886-d94769ece042",
    "workspaceId": "f888d33a-4e28-4668-be3e-6a448040d2ee"
   },
   "lakehouse": {
    "default_lakehouse": "deba868c-6425-4dca-b38e-1e966b35605e",
    "default_lakehouse_name": "lakehouse_bk7",
    "default_lakehouse_workspace_id": "f888d33a-4e28-4668-be3e-6a448040d2ee"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
