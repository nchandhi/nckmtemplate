{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21c97e-3ac4-4659-9ffc-b0774d058bb0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure.cognitiveservices.speech\n",
    "%pip install azure-ai-inference\n",
    "%pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff8856-dbbc-4003-bc18-87e0b630092c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import uuid\n",
    "import azure.cognitiveservices.speech as speechsdk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38648421-e81a-4312-85be-d90e47028449",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "key_vault_name = 'kv_to-be-replaced'\n",
    "index_name = \"call_trascripts_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62559db0-db0d-45db-91e9-40c6c27c6655",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from trident_token_library_wrapper import PyTridentTokenLibrary as tl\n",
    "def get_secrets_from_kv(kv_name, secret_name):\n",
    "    access_token = mssparkutils.credentials.getToken(\"keyvault\")\n",
    "    kv_endpoint = f'https://{kv_name}.vault.azure.net/'\n",
    "    return(tl.get_secret_with_token(kv_endpoint,secret_name,access_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40aafc8-9da9-4826-ae4e-3b23f34621c0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ai_services_key = get_secrets_from_kv(key_vault_name,'AZURE-OPENAI-KEY')\n",
    "ai_services_region = get_secrets_from_kv(key_vault_name, 'AZURE-LOCATION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48078c7-cca4-4366-9070-8164a40330f8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Function to transcribe speech from an audio file\n",
    "def transcribe_from_file(ai_services_key, ai_services_region, wav_file_path, conversation_id):\n",
    "    # List to store the results of the transcription\n",
    "    all_results = list()\n",
    "    \n",
    "    # Configure the speech service\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=ai_services_key, region=ai_services_region)\n",
    "    speech_config.speech_recognition_language = \"en-US\"\n",
    "    \n",
    "    # Set up the audio configuration using the provided file path\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=wav_file_path)\n",
    "    \n",
    "    # Create a conversation transcriber object\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # Flag to indicate when to stop transcribing\n",
    "    transcribing_stop = False\n",
    "\n",
    "    # Callback for when the transcription session starts\n",
    "    def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "        # print('SessionStarted event')\n",
    "        pass\n",
    "\n",
    "    # Callback to signal to stop continuous recognition\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        nonlocal transcribing_stop\n",
    "        transcribing_stop = True\n",
    "        # Log the session ID\n",
    "        # print(f\"Stopping transcription for session id: {evt.session_id}\")\n",
    "\n",
    "        # Check if the event has a result attribute\n",
    "        if hasattr(evt, 'result'):\n",
    "            # If the result reason is cancellation, provide the cancellation details\n",
    "            if evt.result.reason == speechsdk.ResultReason.Canceled:\n",
    "                cancellation_details = speechsdk.CancellationDetails(evt.result)\n",
    "                # print(f\"Transcription was stopped due to cancellation: {cancellation_details.reason}\")\n",
    "                if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "                    print(f\"Error details: {cancellation_details.error_details}\")\n",
    "            # If the result reason is EndOfStream, indicate the audio stream has ended\n",
    "            elif evt.result.reason == speechsdk.ResultReason.EndOfStream:\n",
    "                # print(\"Transcription stopped because the end of the audio stream was reached.\")\n",
    "                pass\n",
    "            # If the result reason is NoMatch, indicate no speech could be recognized\n",
    "            elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "                print(\"Transcription stopped because no speech could be recognized.\")\n",
    "            # For any other reason, log the result reason\n",
    "            else:\n",
    "                print(f\"Transcription stopped for an unknown reason: {evt.result.reason}\")\n",
    "        else:\n",
    "            # If there is no result attribute, log that the reason is unknown\n",
    "            # print(\"Transcription stopped, but no additional information is available.\")\n",
    "            pass\n",
    "\n",
    "    # Callback for when the transcription is canceled\n",
    "    def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "        # print(\"Canceled event\")\n",
    "        # Access the cancellation details from the event\n",
    "        cancellation_details = speechsdk.CancellationDetails(evt.result)\n",
    "        # Print the reason for the cancellation\n",
    "        # print(f\"Canceled event: {cancellation_details.reason}\")\n",
    "\n",
    "        # If there was an error, print the error details\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(f\"Error details: {cancellation_details.error_details}\")\n",
    "\n",
    "\n",
    "    # Callback for when the transcription session stops\n",
    "    def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n",
    "        # Print the session stopped event with the session id for reference\n",
    "        # print(f\"SessionStopped event for session id: {evt.session_id}\")\n",
    "        pass\n",
    "\n",
    "        # If the event has a result attribute, we can check if there are any additional details\n",
    "        if hasattr(evt, 'result') and evt.result:\n",
    "            # Check if the result has a reason attribute and print it\n",
    "            if hasattr(evt.result, 'reason'):\n",
    "                print(f\"Reason for stop: {evt.result.reason}\")\n",
    "\n",
    "            # If the result is a cancellation, print the cancellation details\n",
    "            if evt.result.reason == speechsdk.ResultReason.Canceled:\n",
    "                cancellation_details = speechsdk.CancellationDetails(evt.result)\n",
    "                print(f\"Cancellation reason: {cancellation_details.reason}\")\n",
    "                if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "                    print(f\"Error details: {cancellation_details.error_details}\")\n",
    "\n",
    "\n",
    "    # Handler for the final result of the transcription\n",
    "    def handle_final_result(evt):\n",
    "        nonlocal all_results\n",
    "      \n",
    "        # Check if the event's result is speech recognition with a recognized phrase\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            # Parse the JSON result from the transcription\n",
    "            r = json.loads(evt.result.json)\n",
    "            all_results.append([conversation_id,\n",
    "                                r[\"Id\"],\n",
    "                                r[\"DisplayText\"],\n",
    "                                r[\"Offset\"],\n",
    "                                r[\"Duration\"],\n",
    "                                r[\"Channel\"],\n",
    "                                r[\"Type\"],\n",
    "                                r[\"SpeakerId\"]\n",
    "                                ])\n",
    "        # If the result reason is not recognized speech, log that no recognized speech was found\n",
    "        else:\n",
    "            print(\"No recognized speech was found.\")\n",
    "\n",
    "\n",
    "    # Connect the callbacks to the events fired by the conversation transcriber\n",
    "    conversation_transcriber.transcribed.connect(handle_final_result)\n",
    "    conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n",
    "    conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n",
    "    conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n",
    "    conversation_transcriber.session_stopped.connect(stop_cb)\n",
    "    conversation_transcriber.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start the asynchronous transcription\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "\n",
    "    # Wait for the transcription to complete\n",
    "    while not transcribing_stop:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    # Stop the asynchronous transcription\n",
    "    conversation_transcriber.stop_transcribing_async()\n",
    "    # Return the list of transcribed results\n",
    "    return(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb814142-4d53-4d9b-b1fc-0319f303e2d3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "foldername = 'data_stt'\n",
    "if not mssparkutils.fs.exists(f'Files/{foldername}/'):\n",
    "    mssparkutils.fs.mkdirs(f'Files/{foldername}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c938f-dda7-486b-90b7-5f7d01409215",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "wav_files = []\n",
    "count = 0\n",
    "\n",
    "folder_path ='/lakehouse/default/Files/cu_audio_files'\n",
    "wav_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "\n",
    "for wav_file in wav_files:\n",
    "    file_name = wav_file.split('/')[-1].replace('.wav', '')#.split('_')[1]\n",
    "    \n",
    "    r = transcribe_from_file(ai_services_key,ai_services_region,wav_file,file_name)\n",
    "    \n",
    "    json_obj = {}\n",
    "    content = \"\"\n",
    "    start_time = wav_file.replace(\".wav\", \"\")[-19:]\n",
    "    timestamp_format = \"%Y-%m-%d %H_%M_%S\"\n",
    "    start_timestamp = datetime.strptime(start_time, timestamp_format)\n",
    "    print(start_timestamp)\n",
    "    conversation_id = file_name.split('convo_', 1)[1].split('_')[0]\n",
    "    duration = 0\n",
    "    endTime = \"\"\n",
    "    if len(r) != 0:\n",
    "        for i in r:\n",
    "            duration += i[4]\n",
    "            content += i[2] + \" \"\n",
    "                        \n",
    "            EndTime = str(datetime.strptime(str(start_timestamp), \"%Y-%m-%d %H:%M:%S\") + timedelta(minutes=int(duration)/100000000))\n",
    "            try:\n",
    "                EndTime = str(datetime.strptime(str(EndTime), \"%Y-%m-%d %H:%M:%S.%f\")).split('.')[0]\n",
    "            except:\n",
    "                EndTime = str(datetime.strptime(str(EndTime), \"%Y-%m-%d %H:%M:%S\"))\n",
    "        # print('end time:', EndTime)\n",
    "        # print('duration:', duration) \n",
    "\n",
    "        conversationRow = {\n",
    "            \"ConversationId\": conversation_id,\n",
    "            \"StartTime\": start_time,\n",
    "            \"EndTime\": EndTime,\n",
    "            \"Duration\": duration/100000000,\n",
    "            \"Content\": content,\n",
    "        }\n",
    "        filename = 'convo_' + str(conversation_id) + '_'+ str(start_time) + '.json'\n",
    "        # print(filename)\n",
    "        # print(wav_file)\n",
    "        download_path = f'/lakehouse/default/Files/{foldername}/'\n",
    "\n",
    "        with open(f\"{download_path}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(conversationRow, f, ensure_ascii=False, indent=4) \n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b0fbb-a3f8-4b63-8bd5-aa7ac810da76",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "search_endpoint = get_secrets_from_kv(key_vault_name,\"AZURE-SEARCH-ENDPOINT\")\n",
    "search_key = get_secrets_from_kv(key_vault_name,\"AZURE-SEARCH-KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af35c06-9efc-43dd-b523-cddde72e7c75",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create the search index\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57a698-75d3-453c-8577-d7d88c78e000",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential \n",
    "search_credential = AzureKeyCredential(search_key)\n",
    "# Create a search index \n",
    "index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"chunk_id\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"sourceurl\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        keywords_fields=[SemanticField(field_name=\"chunk_id\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')\n",
    "\n",
    "# Function: Get Embeddings \n",
    "def get_embeddings(text: str,openai_api_base,openai_api_version,openai_api_key):\n",
    "    model_id = \"text-embedding-ada-002\"\n",
    "    client = AzureOpenAI(\n",
    "        api_version=openai_api_version,\n",
    "        azure_endpoint=openai_api_base,\n",
    "        api_key = openai_api_key\n",
    "    )\n",
    "    \n",
    "    embedding = client.embeddings.create(input=text, model=model_id).data[0].embedding\n",
    "\n",
    "    return embedding\n",
    "\n",
    "# Function: Clean Spaces with Regex - \n",
    "def clean_spaces_with_regex(text):\n",
    "    # Use a regular expression to replace multiple spaces with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    # Use a regular expression to replace consecutive dots with a single dot\n",
    "    cleaned_text = re.sub(r'\\.{2,}', '.', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def chunk_data(text):\n",
    "    tokens_per_chunk = 1024 #500\n",
    "    text = clean_spaces_with_regex(text)\n",
    "    SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n",
    "    WORDS_BREAKS = ['\\n', '\\t', '}', '{', ']', '[', ')', '(', ' ', ':', ';', ',']\n",
    "\n",
    "    sentences = text.split('. ') # Split text into sentences\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    current_chunk_token_count = 0\n",
    "    \n",
    "    # Iterate through each sentence\n",
    "    for sentence in sentences:\n",
    "        # Split sentence into tokens\n",
    "        tokens = sentence.split()\n",
    "        \n",
    "        # Check if adding the current sentence exceeds tokens_per_chunk\n",
    "        if current_chunk_token_count + len(tokens) <= tokens_per_chunk:\n",
    "            # Add the sentence to the current chunk\n",
    "            if current_chunk:\n",
    "                current_chunk += '. ' + sentence\n",
    "            else:\n",
    "                current_chunk += sentence\n",
    "            current_chunk_token_count += len(tokens)\n",
    "        else:\n",
    "            # Add current chunk to chunks list and start a new chunk\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = sentence\n",
    "            current_chunk_token_count = len(tokens)\n",
    "    \n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc9026-069c-4de4-b0cf-48a36998401d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# GPT-4o-mini\n",
    "# api_key = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-KEY\")\n",
    "# api_type = \"azure\"\n",
    "# api_version = get_secrets_from_kv(key_vault_name, \"AZURE-OPENAI-PREVIEW-API-VERSION\")\n",
    "# endpoint = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-ENDPOINT\")\n",
    "\n",
    "# endpoint_b = spark.sparkContext.broadcast(endpoint)\n",
    "# api_key_b = spark.sparkContext.broadcast(api_key)\n",
    "# api_version_b = spark.sparkContext.broadcast(api_version)\n",
    "# api_type_b = spark.sparkContext.broadcast(api_type)\n",
    "\n",
    "# Phi-3\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint= get_secrets_from_kv(key_vault_name, \"AZURE-OPENAI-INFERENCE-ENDPOINT\")\n",
    "api_key = get_secrets_from_kv(key_vault_name, \"AZURE-OPENAI-INFERENCE-KEY\")\n",
    "endpoint_b = spark.sparkContext.broadcast(endpoint)\n",
    "api_key_b = spark.sparkContext.broadcast(api_key)\n",
    "\n",
    "# client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e0c0d-2284-4560-aadf-dcb790ee4994",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# get the details of the content from call transcripts\n",
    "def get_details(input_text):\n",
    "    # Construct the prompt  \n",
    "    prompt = f'''You are a JSON formatter for extracting information out of a single chat conversation -\n",
    "            {input_text}\n",
    "            Summarize the conversation, key: summary . \n",
    "            Is the customer satisfied with the agent interaction (Yes or No), key: satisfied . \n",
    "            Identify the sentiment of the conversation (Positive, Neutral, Negative), key: sentiment . \n",
    "            Identify the single primary topic of the conversation in 6 words or less,key: topic . \n",
    "            Identify the top 10 key phrases as comma seperated string excluding people names , key: keyPhrases .\n",
    "            Identify the single primary complaint of the conversation in 3 words or less, key: complaint .\n",
    "            Answer in JSON machine-readable format, using the keys from above. \n",
    "            Pretty print the JSON and make sure that it is properly closed at the end and do not generate any other content.'''\n",
    "\n",
    "    \n",
    "\n",
    "    # working for gpt-4o\n",
    "    # openai.api_base = endpoint_b.value\n",
    "    # openai.api_key =  api_key_b.value\n",
    "    # openai.api_type = api_type_b.value\n",
    "    # openai.api_version = api_version_b.value\n",
    "    \n",
    "    # system_prompt = 'You are a helpful assistant.'\n",
    "    # response = openai.ChatCompletion.create(\n",
    "    # engine=  \"gpt-4o-mini\", #\"gpt-4\", # The deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 model.\n",
    "    # messages=[\n",
    "    #     {\"role\": \"system\", \"content\": system_prompt},\n",
    "    #     {\"role\": \"user\", \"content\": prompt}\n",
    "    # ],\n",
    "    # temperature = 0,\n",
    "    # max_tokens = 2000\n",
    "    # )\n",
    "    # res = response['choices'][0]['message']['content']\n",
    "    # return(json.loads(res.replace(\"```json\",'').replace(\"```\",'')))\n",
    "\n",
    "    ENDPOINT = endpoint_b.value\n",
    "    API_KEY = api_key_b.value\n",
    "    client = ChatCompletionsClient(endpoint=ENDPOINT, credential=AzureKeyCredential(API_KEY))\n",
    "    # Phi-3 model    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            # SystemMessage(content=prompt),\n",
    "            UserMessage(content=prompt),\n",
    "        ],\n",
    "        max_tokens = 500,\n",
    "        temperature = 0,\n",
    "        top_p = 1\n",
    "    )\n",
    "\n",
    "    res = response.choices[0].message.content\n",
    "    return(json.loads(res.replace(\"```json\",'').replace(\"```\",'')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec68d5d-106f-4bcc-950f-d4abae7eea69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "table_name = 'processed_data'\n",
    "df = spark.read.option(\"multiline\", \"true\").json(f\"Files/{foldername}/\")\n",
    "text = df.select('content')\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "             StructField(\"summary\", StringType(), True),\n",
    "             StructField(\"satisfied\", StringType(), True),\n",
    "             StructField(\"sentiment\", StringType(), True),\n",
    "             StructField(\"topic\", StringType(), True),\n",
    "             StructField(\"keyPhrases\", StringType(), True), \n",
    "             StructField(\"complaint\", StringType(), True)\n",
    "         ])\n",
    "\n",
    "get_detail_udf = udf(lambda content: get_details(content),returnType=schema)\n",
    "\n",
    "\n",
    "\n",
    "df_processed = df.select([\"ConversationId\",\"EndTime\",\"StartTime\",\"Content\"]) \\\n",
    "                .withColumn(\"Details\", get_detail_udf(col(\"Content\"))) \\\n",
    "                .select([\"ConversationId\",\"EndTime\",\"StartTime\",\"Content\", \\\n",
    "                          col(\"Details.summary\").alias(\"summary\"), \\\n",
    "                          col(\"Details.satisfied\").alias(\"satisfied\"), \\\n",
    "                          col(\"Details.sentiment\").alias(\"sentiment\"), \\\n",
    "                          col(\"Details.topic\").alias(\"topic\"), \\\n",
    "                          col(\"Details.keyPhrases\").alias(\"keyPhrases\"), \\\n",
    "                          col('Details.complaint').alias(\"complaint\"), \\\n",
    "                          ]) \n",
    "                          \n",
    "df_processed.write.format('delta').mode('append').option(\"overwriteSchema\", \"true\").saveAsTable(table_name)\n",
    "# display(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7d5ed-7fd5-4ff2-8e19-f8c5d1a9050b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "table_name = 'processed_data'\n",
    "sql_stmt = f'select ConversationId, keyPhrases, sentiment, StartTime from {table_name}'\n",
    "df = spark.sql(sql_stmt)\n",
    "df_keyPhrases = df.withColumn('keyPhrases', split(df['keyPhrases'], ','))\n",
    "df_keyPhrases = df_keyPhrases.withColumn('keyPhrase', explode(df_keyPhrases['keyPhrases']))\n",
    "df_keyPhrases = df_keyPhrases.select('ConversationId', 'keyPhrase', 'sentiment')\n",
    "df_keyPhrases.write.format('delta').mode('append').option(\"overwriteSchema\", \"true\").saveAsTable('processed_data_key_phrases')\n",
    "# display(df_keyPhrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac77c1-cd07-4ebc-9382-4815a5537b2d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sql_stmt =\"select ConversationId, StartTime, EndTime, Content, summary, satisfied, keyPhrases, complaint, mined_topic as topic from processed_data\"\n",
    "df = spark.sql(sql_stmt)\n",
    "df.write.format('delta').mode('append').option(\"overwriteSchema\", \"true\").saveAsTable('km_processed_data')\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a497e-4703-4fe7-a07a-e978235ce0eb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from azure.search.documents import SearchClient\n",
    "chunk_num = 0\n",
    "docs = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "path_name = (f'file:/lakehouse/default/Files/{foldername}')\n",
    "paths = mssparkutils.fs.ls(path_name)\n",
    "\n",
    "search_client = SearchClient(search_endpoint, index_name, search_credential)\n",
    "\n",
    "for path in paths: \n",
    "    data = spark.read.option(\"multiline\", \"true\").json(path.path)\n",
    "    text = data.select('Content').collect()[0][0]\n",
    "    filename = path.name.split('/')[-1]\n",
    "    document_id = filename.replace('.json','').replace('convo_','')\n",
    "    \n",
    "    chunks = chunk_data(text)\n",
    "    # print(chunks)\n",
    "    # break\n",
    "    chunk_num = 0\n",
    "    for chunk in chunks:\n",
    "        chunk_num += 1\n",
    "        d = {\n",
    "                \"chunk_id\" : document_id + '_' + str(chunk_num).zfill(2),\n",
    "                \"content\": chunk,       \n",
    "            }\n",
    "        counter += 1\n",
    "        try:\n",
    "            v_contentVector = get_embeddings(str(d[\"content\"]),openai_api_base,openai_api_version,openai_api_key)\n",
    "        except:\n",
    "            time.sleep(30)\n",
    "            # print(d[\"content\"])\n",
    "            try: \n",
    "                v_contentVector = get_embeddings(str(d[\"content\"]),openai_api_base,openai_api_version,openai_api_key)\n",
    "            except: \n",
    "                v_contentVector = []\n",
    "\n",
    "        docs.append(\n",
    "            {\n",
    "                    \"id\": base64.urlsafe_b64encode(bytes(d[\"chunk_id\"], encoding='utf-8')).decode('utf-8'),\n",
    "                    \"chunk_id\": d[\"chunk_id\"],\n",
    "                    \"content\": d[\"content\"],\n",
    "                    \"sourceurl\": path.name.split('/')[-1],\n",
    "                    \"contentVector\": v_contentVector\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if counter % 10 == 0:\n",
    "            result = search_client.upload_documents(documents=docs)\n",
    "            docs = []\n",
    "            print(f' {str(counter)} uploaded')\n",
    "\n",
    "    time.sleep(4)\n",
    "    # upload the last batch\n",
    "    if docs != []:\n",
    "        search_client.upload_documents(documents=docs)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "510c3aa4-bff3-4074-af2d-27d65569dd4f",
    "default_lakehouse_name": "KMLakeHouse",
    "default_lakehouse_workspace_id": "f59a724c-3eae-438f-93bf-2e9e1a4b9edc"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
